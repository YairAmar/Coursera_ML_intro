{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "%matplotlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path: str, add_bias: bool = True) -> tuple:\n",
    "    \"\"\"\n",
    "    Loading data and formatting for the latter linear regression\n",
    "\n",
    "    Args:\n",
    "        path: directory path of the csv file containing the data\n",
    "        add_bias: if True x will be returned with 1 in the first column\n",
    "    Returns:\n",
    "        x: data features\n",
    "        y: data classes\n",
    "    \"\"\"\n",
    "    data = loadmat(path)\n",
    "    x = np.array(data[\"X\"])\n",
    "\n",
    "    if add_bias:\n",
    "        poly = PolynomialFeatures(1)\n",
    "        x = poly.fit_transform(x)\n",
    "\n",
    "    y = np.array(data[\"y\"])\n",
    "    #y[y == 10] = 0\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing data:\n",
    "path = r'C:\\Users\\student\\Hafifa\\ML_intro\\ex3\\data\\ex3data1.mat'\n",
    "x, y = load_data(path, add_bias=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_data(x):\n",
    "    # sample 100 random images\n",
    "    random_index = np.random.randint(0, 5000, 100)\n",
    "    images = x[random_index, :]\n",
    "    plt.figure(figsize=(9,9))\n",
    "    \n",
    "    for i in range(images.shape[0]):\n",
    "        image = np.reshape(images[i,:], (20, 20)).T\n",
    "        plt.subplot(10, 10, i+1)\n",
    "        plt.imshow(image, cmap='gray')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_data(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    sig = 1 / (1 + np.exp(-z))\n",
    "    return sig\n",
    "\n",
    "def compute_cost(theta,x,y):\n",
    "    z = x @ theta\n",
    "    h = sigmoid(z)\n",
    "    cost = -y @ np.log(h) - (1-y) @ np.log(1-h)\n",
    "    return cost\n",
    "\n",
    "def forward(weights, x):\n",
    "        a = x.T\n",
    "        gradients = []\n",
    "\n",
    "        for layer in weights:\n",
    "            a = np.insert(a, 0, 1, axis=0)\n",
    "            z = layer @ a\n",
    "            a = sigmoid(z)\n",
    "            grad = sigmoid_gradient(z)\n",
    "            gradients.append(grad)\n",
    "            \n",
    "        return a, gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the pretrained model:\n",
    "\n",
    "def load_nn_weights(path: str) -> list:\n",
    "    \"\"\"\n",
    "    Loading weights of a pre-trained NN\n",
    "    Args:\n",
    "        path: path to the .mat file\n",
    "\n",
    "    Returns:\n",
    "        theta1: weights of the 1st layer\n",
    "        theta2: weights of the 2nd layer\n",
    "    \"\"\"\n",
    "    weights = loadmat(path)\n",
    "    theta1 = weights[\"Theta1\"]\n",
    "    theta2 = weights[\"Theta2\"]\n",
    "    \n",
    "    return [theta1, theta2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(y, n_classes=10):\n",
    "    y_one_hot = np.zeros((len(y),n_classes))\n",
    "    \n",
    "    for i, j in enumerate(y):\n",
    "        y_one_hot[i,j-1] = 1\n",
    "    \n",
    "    return y_one_hot    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"The constructor of the NN-model object\"\"\"\n",
    "        path = r\"C:\\Users\\student\\Hafifa\\ML_intro\\ex3\\data\\ex3weights.mat\"\n",
    "        self.thetas = init_nn_weights(load_nn_weights(path), epsilon=0.12) #sys.argv[2])\n",
    "\n",
    "    def predict(self, x: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Applies a prediction of the neural-net over x\n",
    "        Args:\n",
    "            x: input data\n",
    "\n",
    "        Returns:\n",
    "            prediction: predicted label for each data-point\n",
    "        \"\"\"\n",
    "        pred,_ = forward(self.thetas, x)\n",
    "        prediction = np.argmax(pred, axis=0).astype(int)\n",
    "        return prediction\n",
    "    \n",
    "    def compute_cost(self, x, y, llambda=0.):\n",
    "        h,_ = forward(self.thetas, x)\n",
    "        y_one_hot = convert_to_one_hot(y)\n",
    "        classification_term = -y_one_hot.T*np.log(h) - (1-y_one_hot).T*np.log(1-h)\n",
    "        cost = np.sum(classification_term)/len(y)\n",
    "        regularization_term = 0\n",
    "        \n",
    "        for layer in self.thetas:\n",
    "            layer_without_bias = layer[:,1:]\n",
    "            regularization_term += np.sum(layer_without_bias**2)\n",
    "            \n",
    "        regularization_term = regularization_term * (llambda /(2*len(y)))\n",
    "        cost += regularization_term\n",
    "        return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25, 401)\n",
      "(10, 26)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.9010629452224865"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NeuralNet()\n",
    "nn.compute_cost(x, y, llambda=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_gradient(z):\n",
    "    sig_grad = sigmoid(z) * (1-sigmoid(z))\n",
    "    return sig_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_nn_weights(weights, epsilon):\n",
    "    new_layers = []\n",
    "    \n",
    "    for layer in weights:\n",
    "        shapee =  layer.shape\n",
    "        print(layer.shape)\n",
    "        layer = np.random.rand(shapee[0],shapee[1]) * 2 * epsilon - epsilon\n",
    "        new_layers.append(layer)\n",
    "    \n",
    "    return new_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
